<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Tlhalefo Boshielo (EVO) Copyright &copy; 2025 3vo1ution. All rights reserved." />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Comfortaa:wght@300..700&family=Maitree:wght@200;300;400;500;600;700&family=Taviraj:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
    <meta name="description" content="BlogsWeek1" />
    <title>Essay 2</title>
    <link rel="stylesheet" href="../CSS/main.css">
    <link rel="stylesheet" href="../CSS/Blog.css">
    <script src="../JS/Main.js"></script>
    <script src="../JS/Blogs.js"></script>


</head>
<body>  
    <header>
        <nav class="NavBar" aria-label="Main Navigation Bar">

                    <div class="MenuToggle" id="MenuToggle">
            <button class="MenuToggleButton" id="ToggleButton">&#9765;</button>
              </div>

            <ul class="NavLinks">
                <li><a class="u-url h-card" href="../index.html">Home</a></li>
                <li><a class="u-url" href="../WrittenWorks/WrittenWorks.html">Scrolls</a></li>
                <li><a class="u-url" href="../DesignFiles/Design.html">Design</a></li>
                <li><a class="u-url" href="../Portfolio/Portfolio.html">Portfolio</a></li>
                <a class="u-url h-card" href="../index.html#Profile">Profile</a>
    
            </ul>

            </nav>  
            </header>
        <nav class="BlogNav" id="BlogNav">
        <ul>
        <li><a class ="BlogNumber u-url h-entry" href="Essay1.html">Essay 1</a></li>
        <li><a class ="BlogNumber u-url h-entry" href="Essay2.html">Essay 2</a></li>
        </ul>
        </nav>

 <h1> Essay 2</h1>

  <div class="h-entry"><p class= “ParagraphContainer” >Amidst the rise of Gen AI tools, we're approaching an age of generative platforms where AI is increasingly prompted with generating images that imitate human culture, style, and memory.  Yet under what seemingly appears to be cultural connecter and facet for creative expression lies the disturbing truth that AI-generated aesthetics often reproduce and perpetuate colonial hierarchies by appropriating and distorting non-Western visual cultures, particularly those associated with Black, Asian and other marginalised communities. This essay argues that AI aesthetics are not neutral but are biassed to Western aesthetics, embedded with racialised, Western logics and epistemologies that reflect and reproduce ongoing systems of Digital coloniality. Using recent events such as the Playstation 2 AI filter trend and the viral rise of Ghibili-inspired AI “art”, this essay explores how algorithmic systems trained of Western-centric datasets,repackage culture in ways that erase its origin, whiten its subjects and recode it for Western consumption. Framing my argument through Seyed Mustafa Ali’s concept of decolonial computing, I investigate how these platforms participate in aesthetic erasure that centres whiteness, flattens cultural depth and strips epistemic justice from communities that birthed the original forms. </p>

<p class= “ParagraphContainer” >The “PS2 nostalgia trend”, which reinterpreted images to have a low-poly retro video game aesthetic, popularised through TikTok and AI image apps within the last year has consistently exemplified the racial bias embedded in generative tools. It was widely noticed by users how the filters frequently tended to lighten skin tones, especially Brown/Lighter skinned people of colour, often rendering them as white people. While such oversights are often dismissed as technical errors, such outputs are shaped by the datasets used to train these models that excessively prioritise whiter-skin tones as default or ideal. These instances of literal “whitewashing” are not accidental but rather reflect deep-rooted racial and systemic hierarchies within these datasets. This reflection of systems of inequality and aesthetic oppression illustrate that “the use of technology tends to reflect, perpetuate and sometimes amplify existing offline social inequalities” (Robinson et al., 2015) as argued by Robinson, Gen AI tools in this sense reinforce existing racial, classist and gendered stereotypes visually and epistemically. </p>

<p class= “ParagraphContainer” >Similarly, the widespread use of "Ghibli Inspired” prompts, which imitate the soft, painterly aesthetic of studio Ghibili’s animated films reveals how AI systems continually unethically extract from culturally specific artistic styles and traditions without care, context or consent. This being exemplified through how Hayao Miyazaki, the co-founder of Studio Ghibli, has publicly expressed his disapproval of AI-generated art, referring to it as  “an insult to human intention”. Even despite his known and public disapproval of the use of these generative tools, Western dominated platforms such as Stable diffusion, Midjourney and even Chat-GPT continued to reproduce Ghibli-like aesthetics, severing them from their Japanese cultural, narrative, and philosophical roots. This flattening of style and cultural erasure for the sake of creating exportable and profitable visual commodities, aligns with Seyd Mustafa Ali’s critiques in “A Brief Introduction to Decolonial Computing”, that argue that “computing systems built on colonial epistemologies, those that prioritise function, replication, and commercial scalability over cultural integrity or relational meaning” (Ali, 2016) </p>

<p class= “ParagraphContainer” >The erasure is not just visual but cultural, contextual, social and epistemological. When cultural forms of expression, like Ghibli’s aesthetic or African hairstyles, are detached from their historical contexts and transformed into promptable content, they are disconnected from their lineage of storytelling, symbolism and resistance. They become reduced to consumable outputs. This adds further emphasis on the questions raised by Ali in asking for the “consideration of the ‘body politics’ and ‘geopolitics’ of knowledge, who is thinking,knowing and remembering and from where and how” (Ali, 2016, p19) in the age of digital coloniality. In relation to AI, these erasures are encoded into the tools themselves, which filter which identities, styles, or worldviews are made visible.</p>

<p class= “ParagraphContainer” >In response to this, what Ali defines as “decolonial computing” (Ali, 2016) offers both a critique of these unjust systems and a challenge. Ali does argue merely for more inclusive datasets or bias fixes. He urges a rethinking of the computational worldview itself stating that “if the inequities of colonial rule have not been erased, it is perhaps premature to proclaim the demise of colonialism” (Ali, 2016, p.18).  This critique calls for a dismantling and dissecting of the assumptions that treat Western-centric aesthetics as the norm, unethically collected data as neutral, and technology as inherently progressive by default. Applying this to Gen AI, the question is not simply whether Ghibli-style art can be replicated ethically, or whether skin tones can be fairly represented, but whether these systems can ever escape the colonial logic at their core. If they cannot, Ali calls for refusal/ “delinking” as a decolonial strategy(Ali, 2016) as practiced by artist like Miyazaki or Black creators who completely avoid the use of generative platforms, as a valid and even radical aesthetic protest against cultural erasure.</p>

<p class= “ParagraphContainer” >At the same time, an alternative decolonial strategy calls for strategic intervention. Could AI be recalibrated with inclusive epistemologies and systems that resist colonial extraction? Could it serve as some Afrocentric projects propose and a tool for cultural memory and speculative repair? The answer may not lie in either full refusal or full participation but an active process of critique and experimentation.</p>

<p class= “ParagraphContainer” >In conclusion, AI aesthetics today participate in a broader system of digital coloniality that extracts from racialised cultures, re-centres whiteness, and flattens and erases the complexity of culture, context and epistemic justice. The PS2 AI trend and the Ghibli diffusion phenomenon are not merely harmless entertainment, but serve rather as cultural case studies in how algorithmic systems reproduce systemic, visual and epistemic power. This inquiry has challenged me to reconsider my role not only as an African existing in digital economies, but as a digital artist/storyteller, not just a consumer or explorer of these technologies, but a guardian of my own culture, narrative and traditions. It highlights the importance of rejecting intellectual passivity, and playing an active role in the deconstruction of these unjust systems, further emphasizing  the urgency to create, code, and critique from a place of deep knowledge, inclusivity and care. If we are to decolonise AI, it must be an active process, we must do more than diversify its outputs, and also critique and question the foundation, systems and datasets used to train these , models and imagine new digital futures shaped not by extraction, inequality and exploitation but by sovereignty, relation, and care.</p>

<section id="references">
  <h2>References</h2>
  <ol>
    <li>
      <cite>
        Ali, S.M. (2016).
        <em>A Brief Introduction to Decolonial Computing. </em>.
        XRDS: Crossroads, The ACM Magazine for Students, 22(4), pp.16–21.
      </cite>
    </li>

    <li>
      <cite>
        Magenya, S. (2020).  <em>Making a Feminist Internet in Africa: Why the Internet Needs African Feminists and Feminisms. </em> GenderIT.org. Available at: 
        <a href="https://www.genderit.org/editorial/making-feminist-internet-africa-why-internet-needs-african-feminists-and-feminisms.
" target="_blank" rel="noopener noreferrer">
          https://www.aufaitux.com/blog/ethical-ux-design/
        </a>.
      </cite>
    </li>
    <li>
      <cite>
        Robinson, L., Cotten, S.R., Ono, H., Quan-Haase, A., Mesch, G., Chen, W., Schulz, J., Hale, T.M. and Stern, M.J. (2015). 
        <em>Digital inequalities and why they matter</em>. <strong>Information, Communication & Society</strong>, 18(5), pp.569–582. 
        doi: 
        <a href="https://doi.org/10.1080/1369118x.2015.1012532" target="_blank" rel="noopener noreferrer">
          https://doi.org/10.1080/1369118x.2015.1012532
        </a>.
</li>
    </ol>
    </section>

 </div>

<footer class="FooterContainer">
  <div class="FooterContent">
    <p class="FooterText">
      &copy; 2025 Tlhalefo Boshielo (EVO) · All rights reserved.
      This site and its contents are part of a creative portfolio. Unauthorized reproduction or distribution is prohibited.
    </p>
    <div class="SocialMediaIcons">
      <a href="https://www.instagram.com/ev0.jpeg?utm_source=ig_web_button_share_sheet&igsh=ZDNlZDc0MzIxNw==" class="SocialLink">
        <img id="IGIcon" src="../Images/InstagramLogo.png" alt="Instagram">
      </a>
    </div>
  </div>
</footer>

 </body>
